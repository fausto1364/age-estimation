{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fausto1364/age-estimation/blob/main/age_estimation_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oP948sesdx2"
      },
      "source": [
        "Age estimation using AlexNet based architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA8uNcAfAV2O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "\n",
        "# image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9263BDgsXv7",
        "outputId": "879a48b7-af10-4ba0-913e-6ded7f6895d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive to access APPA-REAL\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path='/content/drive/MyDrive/appa-real-release/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rxaCu1-Dg5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "53ffc137-321d-41d7-be76-fa4ac12da29d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"image = Image.open(os.path.join(path,'005612.jpg_face.jpg'))\\nimage.show()\\nprint(image.format)\\nprint(image.mode)\\nprint(image.size)\\ntest = image.resize((64,64))\\ntest.show()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# just to store comands for Image...\n",
        "'''image = Image.open(os.path.join(path,'005612.jpg_face.jpg'))\n",
        "image.show()\n",
        "print(image.format)\n",
        "print(image.mode)\n",
        "print(image.size)\n",
        "test = image.resize((64,64))\n",
        "test.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5GtgdloFV9_"
      },
      "outputs": [],
      "source": [
        "# extracts only face detected jpegs. Then rescales size of image and converts to numpy matrix\n",
        "def preprocess(folder_path,size):\n",
        "  X=[] # contains processed images\n",
        "  y=[] # contains ids of images\n",
        "  # regular expression pattern to only extract files with face detection\n",
        "  pattern = r\"\\d+\\.jpg_face\\.jpg\"\n",
        "\n",
        "  # Loop over all files in the folder\n",
        "  for imagename in os.listdir(folder_path):\n",
        "    image_path = os.path.join(folder_path, imagename)\n",
        "\n",
        "    if re.match(pattern, imagename):\n",
        "      image = Image.open(image_path)\n",
        "      image = image.resize(size)\n",
        "      array = [[np.float32(value) for value in row] for row in image.getdata()]\n",
        "      X.append(np.array(array).reshape(image.size[1], image.size[0], 3))\n",
        "      y.append(imagename.split(\".\")[0])\n",
        "  return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-In5DH1SvJzW"
      },
      "outputs": [],
      "source": [
        "# read the csv files with the apparent ages\n",
        "def get_appaages(path):\n",
        "  id = []\n",
        "  appa_age = []\n",
        "\n",
        "  # Read the CSV file\n",
        "  with open(path, \"r\") as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "\n",
        "    # Skip header\n",
        "    next(csv_reader)\n",
        "\n",
        "    # Iterate over each row in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Append the values of the first and third columns to their respective lists\n",
        "        id.append(row[0].split(\".\")[0])\n",
        "        appa_age.append(row[2])\n",
        "\n",
        "  return appa_age, id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t9O9lW1CFmK"
      },
      "outputs": [],
      "source": [
        "# allign two lists according to lists with ids\n",
        "def allign_lists(A,a,B,b):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for i in range(len(A)):\n",
        "    X.append(A[i])\n",
        "    Y.append(np.float32(B[b.index(a[i])]))\n",
        "\n",
        "  return np.array(X),np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5fPAm-7wM4J"
      },
      "outputs": [],
      "source": [
        "# extract and preprocess images\n",
        "train_path = os.path.join(path, 'train/')\n",
        "valid_path = os.path.join(path, 'valid/')\n",
        "test_path = os.path.join(path, 'test/')\n",
        "\n",
        "images_train,ids_train_im = preprocess(train_path,(64,64))\n",
        "images_valid,ids_valid_im = preprocess(valid_path,(64,64))\n",
        "images_test,ids_test_im = preprocess(test_path,(64,64))\n",
        "\n",
        "# extract apparent ages\n",
        "gt_train = os.path.join(path, 'gt_avg_train.csv')\n",
        "gt_valid = os.path.join(path, 'gt_avg_valid.csv')\n",
        "gt_test = os.path.join(path, 'gt_avg_test.csv')\n",
        "\n",
        "appaages_train, ids_train_gt = get_appaages(gt_train)\n",
        "appaages_valid, ids_valid_gt = get_appaages(gt_valid)\n",
        "appaages_test, ids_test_gt = get_appaages(gt_test)\n",
        "\n",
        "# sort apparent ages by images through the ids\n",
        "images_train, appaages_train = allign_lists(images_train, ids_train_im, appaages_train, ids_train_gt)\n",
        "images_valid, appaages_valid = allign_lists(images_valid, ids_valid_im, appaages_valid, ids_valid_gt)\n",
        "images_test, appaages_test = allign_lists(images_test, ids_test_im, appaages_test, ids_test_gt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaFZZaPu49GM"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "train_data = data.TensorDataset(torch.tensor(images_train), torch.tensor(appaages_train))\n",
        "test_data = data.TensorDataset(torch.tensor(images_test), torch.tensor(appaages_test))\n",
        "valid_data = data.TensorDataset(torch.tensor(images_valid), torch.tensor(appaages_valid))\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32\n",
        "train_dataloader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(test_data, batch_size=batch_size)\n",
        "valid_dataloader = data.DataLoader(valid_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNmethods(nn.Module):\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.mse_loss(out, labels)      # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.mse_loss(out, labels)        # Calculate loss\n",
        "        return {'val_loss': loss.detach()}\n",
        "    '''\n",
        "    def validation_step_MAE(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)\n",
        "        loss = nn.L1Loss() # L1 loss as MAE\n",
        "        return {'val_loss_MAE': loss.detach()}'''\n",
        "\n",
        "    '''\n",
        "    def test_step...\n",
        "\n",
        "    def test_step_MAE\n",
        "\n",
        "    '''\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()    # Combine losses\n",
        "\n",
        "        #batch_accs = [x['val_acc'] for x in outputs]\n",
        "        #epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    '''\n",
        "    def validation_epoch_end_MAE(self, outputs):\n",
        "        batch_losses_MAE = [x['val_loss_MAE'] for x in outputs]\n",
        "        epoch_loss_MAE = torch.stack(batch_losses_MAE).mean()    # Combine losses\n",
        "        return {'val_loss_MAE': epoch_loss_MAE.item()}'''\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss']))"
      ],
      "metadata": {
        "id": "lPRNT59IDQ8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QEwE2Zgs9nI"
      },
      "outputs": [],
      "source": [
        "# do the architecture. Basic, simple one\n",
        "class AgeEstimation(CNNmethods):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.batchnorm1 = nn.BatchNorm2d(16)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(32)\n",
        "    self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    self.fc1 = nn.Linear(64 * 16 * 4, 1024)\n",
        "    self.fc2 = nn.Linear(1024, 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.batchnorm3(x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = x.squeeze(1)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "'''\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "'''\n",
        "def evaluate_MAE(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step_MAE(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end_MAE(outputs)'''\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        result = evaluate(model, val_loader)\n",
        "        #result['val_loss_MAE'] = evaluate_MAE(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "DMW_8VMOKbd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7rUneFq60m3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "d39ac47b-4339-4bd8-da60-711006027540"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 309.0258, val_loss: 361.9072\n",
            "Epoch [1], train_loss: 240.0415, val_loss: 232.6223\n",
            "Epoch [2], train_loss: 213.6335, val_loss: 198.4247\n",
            "Epoch [3], train_loss: 194.7472, val_loss: 183.9462\n",
            "Epoch [4], train_loss: 181.3145, val_loss: 190.0264\n",
            "Epoch [5], train_loss: 164.3718, val_loss: 172.5839\n",
            "Epoch [6], train_loss: 154.6540, val_loss: 178.4245\n",
            "Epoch [7], train_loss: 138.3146, val_loss: 200.6656\n",
            "Epoch [8], train_loss: 141.9068, val_loss: 163.5956\n",
            "Epoch [9], train_loss: 131.8756, val_loss: 169.3305\n",
            "Epoch [10], train_loss: 119.4224, val_loss: 173.5663\n",
            "Epoch [11], train_loss: 113.3776, val_loss: 175.3191\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f33c18f24a2c>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fitting the model on training data and record the result after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-a497cde8ac94>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.005\n",
        "model = AgeEstimation()\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# fitting the model on training data and record the result after each epoch\n",
        "history = fit(num_epochs, lr, model, train_dataloader, valid_dataloader, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    \"\"\" Plot the losses in each epoch\"\"\"\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses[1:], '-bx') # leave out first as this will distort everything (no range defined)\n",
        "    plt.plot(val_losses[1:], '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "r4Fsy52ULdJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "More things to consider are these:\n",
        "\n",
        "*   Check on the test set how the model performed\n",
        "*   Calculate MAE (Mean Absolute Error) to compare to https://github.com/yu4u/age-gender-estimation/blob/master/README.md\n",
        "*   How to make results reproducable"
      ],
      "metadata": {
        "id": "Z_cB9tUQObZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_MAE_MSE(dataloader):\n",
        "    # calculates MAE on test set\n",
        "    model.eval()\n",
        "    MAE=0\n",
        "    count=0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        with torch.no_grad():\n",
        "            output = model(images)\n",
        "            for i in range(len(labels)):\n",
        "                MAE = MAE + abs(float(output[i])-float(labels[i]))\n",
        "                count+=1\n",
        "\n",
        "\n",
        "    MAE = MAE/count\n",
        "\n",
        "    print('MAE')\n",
        "    print(MAE)\n",
        "\n",
        "    # calculates MSE on test set\n",
        "    model.eval()\n",
        "    MSE=0\n",
        "    count=0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        with torch.no_grad():\n",
        "            output = model(images)\n",
        "            for i in range(len(labels)):\n",
        "                MSE = MSE + (float(output[i])-float(labels[i]))**2\n",
        "                count+=1\n",
        "\n",
        "\n",
        "    MSE = MSE/count\n",
        "    print('MSE')\n",
        "    print(MSE)\n",
        "    return\n",
        "\n",
        "print('train')\n",
        "calculate_MAE_MSE(train_dataloader)\n",
        "print('valid')\n",
        "calculate_MAE_MSE(valid_dataloader)\n",
        "print('test')\n",
        "calculate_MAE_MSE(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ovAffqOah_",
        "outputId": "03553d50-579a-4f9a-d6c0-ae528ebfb94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.430136906225375\n",
            "31.972042915102154\n",
            "9.657216502308845\n",
            "160.26258010253596\n",
            "10.969831329957781\n",
            "216.08329354029152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some weird problems with this architecture from (https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/)\n",
        "'''class LeNet(nn.Module):\n",
        "    def __init__(self, numChannels):\n",
        "\t\t    # call the parent constructor\n",
        "\t\t    super(LeNet, self).__init__()\n",
        "\t\t    # initialize first set of CONV => RELU => POOL layers\n",
        "\t\t    self.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n",
        "\t\t    self.relu1 = nn.ReLU()\n",
        "\t\t    self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t    # initialize second set of CONV => RELU => POOL layers\n",
        "\t\t    self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
        "\t\t    self.relu2 = nn.ReLU()\n",
        "\t\t    self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t    # initialize first (and only) set of FC => RELU layers\n",
        "\t\t    self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
        "\t\t    self.relu3 = nn.ReLU()\n",
        "\t\t    # initialize our softmax classifier\n",
        "\t\t    self.fc2 = nn.Linear(in_features=500, out_features=1)\n",
        "\t\t    self.logSoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\t\t    # pass the input through our first set of CONV => RELU =>\n",
        "\t\t    # POOL layers\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.relu1(x)\n",
        "\t\tx = self.maxpool1(x)\n",
        "\t\t# pass the output from the previous layer through the second\n",
        "\t\t# set of CONV => RELU => POOL layers\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.relu2(x)\n",
        "\t\tx = self.maxpool2(x)\n",
        "\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t# through our only set of FC => RELU layers\n",
        "\t\tx = nn.flatten(x, 1)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.relu3(x)\n",
        "\t\t# pass the output to our softmax classifier to get our output\n",
        "\t\t# predictions\n",
        "\t\tx = self.fc2(x)\n",
        "\t\toutput = self.logSoftmax(x)\n",
        "\t\t# return the output predictions\n",
        "\t\treturn output'''"
      ],
      "metadata": {
        "id": "FL6CjRsjex6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11r4otEFT2crPr0bsoxXYV_XxY-Yr0VHA",
      "authorship_tag": "ABX9TyO898Ip4lz9f7teLnILULKM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}