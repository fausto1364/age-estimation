{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fausto1364/age-estimation/blob/main/age_estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oP948sesdx2"
      },
      "source": [
        "Age estimation using AlexNet based architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iA8uNcAfAV2O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import uuid\n",
        "\n",
        "# image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# deep learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9263BDgsXv7",
        "outputId": "bbdd3037-239e-4b8d-f86f-958ca6d45597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount drive to access APPA-REAL\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path='/content/drive/MyDrive/appa-real-release/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7rxaCu1-Dg5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52b07bf8-9b83-4a63-8949-9b983c56d1ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"image = Image.open(os.path.join(path,'005612.jpg_face.jpg'))\\nimage.show()\\nprint(image.format)\\nprint(image.mode)\\nprint(image.size)\\ntest = image.resize((64,64))\\ntest.show()\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# just to store comands for Image...\n",
        "'''image = Image.open(os.path.join(path,'005612.jpg_face.jpg'))\n",
        "image.show()\n",
        "print(image.format)\n",
        "print(image.mode)\n",
        "print(image.size)\n",
        "test = image.resize((64,64))\n",
        "test.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D5GtgdloFV9_"
      },
      "outputs": [],
      "source": [
        "# extracts only face detected jpegs. Then rescales size of image and converts to numpy matrix\n",
        "def preprocess(folder_path,size):\n",
        "  X=[] # contains processed images\n",
        "  y=[] # contains ids of images\n",
        "  # regular expression pattern to only extract files with face detection\n",
        "  pattern = r\"\\d+\\.jpg_face\\.jpg\"\n",
        "\n",
        "  # Loop over all files in the folder\n",
        "  for imagename in os.listdir(folder_path):\n",
        "    image_path = os.path.join(folder_path, imagename)\n",
        "    \n",
        "    if re.match(pattern, imagename):\n",
        "      image = Image.open(image_path)\n",
        "      image = image.resize(size)\n",
        "      array = [[np.float32(value) for value in row] for row in image.getdata()]\n",
        "      X.append(np.array(array).reshape(image.size[1], image.size[0], 3))\n",
        "      y.append(imagename.split(\".\")[0])\n",
        "  return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-In5DH1SvJzW"
      },
      "outputs": [],
      "source": [
        "# read the csv files with the apparent ages\n",
        "def get_appaages(path):\n",
        "  id = []\n",
        "  appa_age = []\n",
        "\n",
        "  # Read the CSV file\n",
        "  with open(path, \"r\") as csv_file:\n",
        "    csv_reader = csv.reader(csv_file)\n",
        "    \n",
        "    # Skip header\n",
        "    next(csv_reader)\n",
        "    \n",
        "    # Iterate over each row in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Append the values of the first and third columns to their respective lists\n",
        "        id.append(row[0].split(\".\")[0])\n",
        "        appa_age.append(row[2])\n",
        "\n",
        "  return appa_age, id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2t9O9lW1CFmK"
      },
      "outputs": [],
      "source": [
        "# allign two lists according to lists with ids\n",
        "def allign_lists(A,a,B,b):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  for i in range(len(A)):\n",
        "    X.append(A[i])\n",
        "    Y.append(np.float32(B[b.index(a[i])]))\n",
        "\n",
        "  return np.array(X),np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G5fPAm-7wM4J"
      },
      "outputs": [],
      "source": [
        "# extract and preprocess images\n",
        "train_path = os.path.join(path, 'train')\n",
        "valid_path = os.path.join(path, 'valid')\n",
        "test_path = os.path.join(path, 'test')\n",
        "\n",
        "images_train,ids_train_im = preprocess(train_path,(64,64))\n",
        "images_valid,ids_valid_im = preprocess(valid_path,(64,64))\n",
        "images_test,ids_test_im = preprocess(test_path,(64,64))\n",
        "\n",
        "# extract apparent ages\n",
        "gt_train = os.path.join(path, 'gt_avg_train.csv')\n",
        "gt_valid = os.path.join(path, 'gt_avg_valid.csv')\n",
        "gt_test = os.path.join(path, 'gt_avg_test.csv')\n",
        "\n",
        "appaages_train, ids_train_gt = get_appaages(gt_train)\n",
        "appaages_valid, ids_valid_gt = get_appaages(gt_valid)\n",
        "appaages_test, ids_test_gt = get_appaages(gt_test)\n",
        "\n",
        "# sort apparent ages by images through the ids\n",
        "images_train, appaages_train = allign_lists(images_train, ids_train_im, appaages_train, ids_train_gt)\n",
        "images_valid, appaages_valid = allign_lists(images_valid, ids_valid_im, appaages_valid, ids_valid_gt)\n",
        "images_test, appaages_test = allign_lists(images_test, ids_test_im, appaages_test, ids_test_gt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HaFZZaPu49GM"
      },
      "outputs": [],
      "source": [
        "# Convert data to PyTorch tensors\n",
        "train_data = data.TensorDataset(torch.tensor(images_train), torch.tensor(appaages_train))\n",
        "test_data = data.TensorDataset(torch.tensor(images_test), torch.tensor(appaages_test))\n",
        "valid_data = data.TensorDataset(torch.tensor(images_valid), torch.tensor(appaages_valid))\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 32\n",
        "train_dataloader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = data.DataLoader(test_data, batch_size=batch_size)\n",
        "valid_dataloader = data.DataLoader(valid_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNmethods(nn.Module):\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "lPRNT59IDQ8C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3QEwE2Zgs9nI"
      },
      "outputs": [],
      "source": [
        "# do the architecture. Basic, simple one\n",
        "class AgeEstimation(CNNmethods):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc_layers = nn.Sequential(\n",
        "      nn.Linear(16 * 32 * 32, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "    x = self.layers(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    #x = torch.flatten(x, 1)\n",
        "    #print(\"Input shape:\", x.shape)\n",
        "    x = self.fc_layers(x)\n",
        "    #print(\"Output shape:\", x.shape)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "  \n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "  \n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n",
        "    \n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(),lr)\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "DMW_8VMOKbd2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j7rUneFq60m3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "1d7b1196-4bfc-4318-a4e2-6abda4928c39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-21f5d0566e1e>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#fitting the model on training data and record the result after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-ce213bce9de3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-68456906ddbc>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Long but found Float"
          ]
        }
      ],
      "source": [
        "num_epochs = 30\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n",
        "model = AgeEstimation()\n",
        "\n",
        "#fitting the model on training data and record the result after each epoch\n",
        "history = fit(num_epochs, lr, model, train_dataloader, valid_dataloader, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    \"\"\" Plot the history of accuracies\"\"\"\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "def plot_losses(history):\n",
        "    \"\"\" Plot the losses in each epoch\"\"\"\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "metadata": {
        "id": "r4Fsy52ULdJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)\n",
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "LYup8_OzLf5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pfxmQpe64Ii"
      },
      "outputs": [],
      "source": [
        "# do the training\n",
        "'''num_epochs = 10\n",
        "\n",
        "H = {\n",
        "\t\"train_loss\": [],\n",
        "\t\"train_acc\": [],\n",
        "\t\"val_loss\": [],\n",
        "\t\"val_acc\": []\n",
        "}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    validation_loss = 0.0\n",
        "\n",
        "    train_correct = 0\n",
        "    validation_correct = 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()'''\n",
        "'''\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print average loss for each epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_dataloader):.4f}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLMDVKeQtDiT"
      },
      "outputs": [],
      "source": [
        "'''# do the evaluation\n",
        "model.eval()\n",
        "total_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.permute(0, 3, 1, 2)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(test_dataloader)\n",
        "    print(f\"Test Loss: {average_loss:.4f}\")'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some weird problems with this architecture from (https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/)\n",
        "'''class LeNet(nn.Module):\n",
        "    def __init__(self, numChannels):\n",
        "\t\t    # call the parent constructor\n",
        "\t\t    super(LeNet, self).__init__()\n",
        "\t\t    # initialize first set of CONV => RELU => POOL layers\n",
        "\t\t    self.conv1 = nn.Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n",
        "\t\t    self.relu1 = nn.ReLU()\n",
        "\t\t    self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t    # initialize second set of CONV => RELU => POOL layers\n",
        "\t\t    self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=(5, 5))\n",
        "\t\t    self.relu2 = nn.ReLU()\n",
        "\t\t    self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t    # initialize first (and only) set of FC => RELU layers\n",
        "\t\t    self.fc1 = nn.Linear(in_features=800, out_features=500)\n",
        "\t\t    self.relu3 = nn.ReLU()\n",
        "\t\t    # initialize our softmax classifier\n",
        "\t\t    self.fc2 = nn.Linear(in_features=500, out_features=1)\n",
        "\t\t    self.logSoftmax = nn.LogSoftmax(dim=1)\n",
        "  \n",
        "    def forward(self, x):\n",
        "\t\t    # pass the input through our first set of CONV => RELU =>\n",
        "\t\t    # POOL layers\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.relu1(x)\n",
        "\t\tx = self.maxpool1(x)\n",
        "\t\t# pass the output from the previous layer through the second\n",
        "\t\t# set of CONV => RELU => POOL layers\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.relu2(x)\n",
        "\t\tx = self.maxpool2(x)\n",
        "\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t# through our only set of FC => RELU layers\n",
        "\t\tx = nn.flatten(x, 1)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.relu3(x)\n",
        "\t\t# pass the output to our softmax classifier to get our output\n",
        "\t\t# predictions\n",
        "\t\tx = self.fc2(x)\n",
        "\t\toutput = self.logSoftmax(x)\n",
        "\t\t# return the output predictions\n",
        "\t\treturn output'''"
      ],
      "metadata": {
        "id": "FL6CjRsjex6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11r4otEFT2crPr0bsoxXYV_XxY-Yr0VHA",
      "authorship_tag": "ABX9TyMT2VxHcQuhCz2E86oT4cVh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}